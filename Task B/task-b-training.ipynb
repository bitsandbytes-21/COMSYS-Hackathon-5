{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12309085,"sourceType":"datasetVersion","datasetId":7758580}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training using MobileNetV2","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport tensorflow as tf\nfrom glob import glob\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Layer\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:07:08.404082Z","iopub.execute_input":"2025-07-04T07:07:08.404276Z","iopub.status.idle":"2025-07-04T07:07:21.837410Z","shell.execute_reply.started":"2025-07-04T07:07:08.404259Z","shell.execute_reply":"2025-07-04T07:07:21.836689Z"}},"outputs":[{"name":"stderr","text":"2025-07-04 07:07:09.938862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751612830.115143      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751612830.165192      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:33.838345Z","iopub.execute_input":"2025-07-04T07:21:33.839036Z","iopub.status.idle":"2025-07-04T07:21:34.876566Z","shell.execute_reply.started":"2025-07-04T07:21:33.839007Z","shell.execute_reply":"2025-07-04T07:21:34.875720Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def get_all_images(root_dir):\n    person_images = {}\n    for person in os.listdir(root_dir):\n        person_path = os.path.join(root_dir, person)\n        if os.path.isdir(person_path):\n            distorted_folder = os.path.join(person_path, 'distortion')\n            distorted_images = glob(os.path.join(distorted_folder, '*.jpg'))\n            clean_images = [f for f in glob(os.path.join(person_path, '*.jpg')) if 'distortion' not in f]\n            if len(clean_images) >= 1 and len(distorted_images) >= 1:\n                person_images[person_path] = {\n                    'clean': clean_images,\n                    'distorted': distorted_images\n                }\n    return person_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:37.292853Z","iopub.execute_input":"2025-07-04T07:21:37.293512Z","iopub.status.idle":"2025-07-04T07:21:37.300681Z","shell.execute_reply.started":"2025-07-04T07:21:37.293480Z","shell.execute_reply":"2025-07-04T07:21:37.299591Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def create_pairs(person_images, num_neg_pairs=5000):\n    pairs = []\n    persons = list(person_images.keys())\n    for person in persons:\n        clean_imgs = person_images[person]['clean']\n        distorted_imgs = person_images[person]['distorted']\n        for c in clean_imgs:\n            for d in distorted_imgs:\n                pairs.append((c, d, 1))\n        for i in range(len(clean_imgs)):\n            for j in range(i + 1, len(clean_imgs)):\n                pairs.append((clean_imgs[i], clean_imgs[j], 1))\n        for i in range(len(distorted_imgs)):\n            for j in range(i + 1, len(distorted_imgs)):\n                pairs.append((distorted_imgs[i], distorted_imgs[j], 1))\n    while len([p for p in pairs if p[2] == 0]) < num_neg_pairs:\n        p1, p2 = random.sample(persons, 2)\n        img1 = random.choice(person_images[p1]['clean'] + person_images[p1]['distorted'])\n        img2 = random.choice(person_images[p2]['clean'] + person_images[p2]['distorted'])\n        pairs.append((img1, img2, 0))\n    return pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:41.260391Z","iopub.execute_input":"2025-07-04T07:21:41.261046Z","iopub.status.idle":"2025-07-04T07:21:41.267289Z","shell.execute_reply.started":"2025-07-04T07:21:41.261021Z","shell.execute_reply":"2025-07-04T07:21:41.266641Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def preprocess(path):\n    byte_img = tf.io.read_file(path)\n    img = tf.io.decode_jpeg(byte_img, channels=3)\n    img = tf.image.resize(img, (160, 160))\n    img = preprocess_input(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:44.754237Z","iopub.execute_input":"2025-07-04T07:21:44.755059Z","iopub.status.idle":"2025-07-04T07:21:44.760469Z","shell.execute_reply.started":"2025-07-04T07:21:44.755025Z","shell.execute_reply":"2025-07-04T07:21:44.759362Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocess_pair(path1, path2, label):\n    return (preprocess(path1), preprocess(path2), tf.convert_to_tensor(label))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:47.386508Z","iopub.execute_input":"2025-07-04T07:21:47.387252Z","iopub.status.idle":"2025-07-04T07:21:47.390994Z","shell.execute_reply.started":"2025-07-04T07:21:47.387230Z","shell.execute_reply":"2025-07-04T07:21:47.390077Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def get_tf_dataset(pairs):\n    path1 = [p[0] for p in pairs]\n    path2 = [p[1] for p in pairs]\n    labels = [p[2] for p in pairs]\n    ds1 = tf.data.Dataset.from_tensor_slices(path1)\n    ds2 = tf.data.Dataset.from_tensor_slices(path2)\n    lbls = tf.data.Dataset.from_tensor_slices(labels)\n    dataset = tf.data.Dataset.zip((ds1, ds2, lbls))\n    dataset = dataset.map(preprocess_pair, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.shuffle(2048).batch(64).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:49.956722Z","iopub.execute_input":"2025-07-04T07:21:49.957007Z","iopub.status.idle":"2025-07-04T07:21:49.962302Z","shell.execute_reply.started":"2025-07-04T07:21:49.956986Z","shell.execute_reply":"2025-07-04T07:21:49.961567Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class L1Dist(Layer):\n    def __init__(self, **kwargs):\n        super().__init__()\n    def call(self, input_embedding, validation_embedding):\n        return tf.math.abs(input_embedding - validation_embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:55.577826Z","iopub.execute_input":"2025-07-04T07:21:55.578092Z","iopub.status.idle":"2025-07-04T07:21:55.582366Z","shell.execute_reply.started":"2025-07-04T07:21:55.578072Z","shell.execute_reply":"2025-07-04T07:21:55.581694Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def make_embedding(trainable=False):\n    base_model = MobileNetV2(include_top=False, input_shape=(160, 160, 3), pooling='avg', weights='imagenet')\n    base_model.trainable = trainable\n    inputs = Input(shape=(160, 160, 3))\n    x = base_model(inputs)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(128, activation='sigmoid')(x)\n    return Model(inputs, x, name='MobileNetV2_Embedding')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:21:58.195283Z","iopub.execute_input":"2025-07-04T07:21:58.195560Z","iopub.status.idle":"2025-07-04T07:21:58.200180Z","shell.execute_reply.started":"2025-07-04T07:21:58.195539Z","shell.execute_reply":"2025-07-04T07:21:58.199482Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"embedding_model = make_embedding(trainable=False)\ndef make_siamese_model():\n    input_image = Input(name='input_img', shape=(160, 160, 3))\n    validation_image = Input(name='validation_img', shape=(160, 160, 3))\n    distances = L1Dist()(embedding_model(input_image), embedding_model(validation_image))\n    outputs = Dense(1, activation='sigmoid')(distances)\n    return Model(inputs=[input_image, validation_image], outputs=outputs, name='SiameseNetwork')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:22:02.594347Z","iopub.execute_input":"2025-07-04T07:22:02.594615Z","iopub.status.idle":"2025-07-04T07:22:05.276300Z","shell.execute_reply.started":"2025-07-04T07:22:02.594596Z","shell.execute_reply":"2025-07-04T07:22:05.275531Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1751613722.858351      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1751613722.859078      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"TRAIN_ROOT = \"/kaggle/input/comsys-taskb/Comys_Hackathon5/Task_B/train\"\ntrain_images = get_all_images(TRAIN_ROOT)\ntrain_pairs = create_pairs(train_images, num_neg_pairs=5000)\ntrain_pairs = random.sample(train_pairs, 200000)\ntrain_data = get_tf_dataset(train_pairs)\n\nsiamese_model = make_siamese_model()\nloss_fn = tf.losses.BinaryCrossentropy()\noptimizer = tf.keras.optimizers.Adam(1e-4)\ntrain_auc = tf.keras.metrics.AUC()\n\n@tf.function\ndef train_step(batch):\n    with tf.GradientTape() as tape:\n        x = batch[:2]\n        y = tf.cast(batch[2], tf.float32)\n        yhat = siamese_model(x, training=True)\n        loss = loss_fn(y, yhat)\n        train_auc.update_state(y, yhat)\n    gradients = tape.gradient(loss, siamese_model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, siamese_model.trainable_variables))\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:22:08.472286Z","iopub.execute_input":"2025-07-04T07:22:08.473010Z","iopub.status.idle":"2025-07-04T07:25:54.362864Z","shell.execute_reply.started":"2025-07-04T07:22:08.472988Z","shell.execute_reply":"2025-07-04T07:25:54.362118Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train_model(train_data, epochs=5):\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        progbar = tf.keras.utils.Progbar(len(train_data))\n        for idx, batch in enumerate(train_data):\n            loss = train_step(batch)\n            progbar.update(idx + 1)\n        print(f\"\\nEpoch {epoch+1} AUC: {train_auc.result().numpy():.4f}\")\n        train_auc.reset_state()\n\n        # Unfreeze MobileNetV2 after 2 epochs\n        if epoch == 1:\n            print(\"\\nUnfreezing MobileNetV2 for fine-tuning...\")\n            base_model = embedding_model.get_layer('mobilenetv2_1.00_160')\n            base_model.trainable = True\n            for layer in base_model.layers[:100]:\n                layer.trainable = False\n            optimizer.learning_rate.assign(1e-5)\n\ntrain_model(train_data, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:26:44.829976Z","iopub.execute_input":"2025-07-04T07:26:44.830283Z","iopub.status.idle":"2025-07-04T07:52:43.672149Z","shell.execute_reply.started":"2025-07-04T07:26:44.830263Z","shell.execute_reply":"2025-07-04T07:52:43.671522Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751614019.785932      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 98ms/step\n\nEpoch 1 AUC: 0.5564\nEpoch 2/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 98ms/step\n\nEpoch 2 AUC: 0.6825\n\nUnfreezing MobileNetV2 for fine-tuning...\nEpoch 3/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 98ms/step\n\nEpoch 3 AUC: 0.8172\nEpoch 4/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 98ms/step\n\nEpoch 4 AUC: 0.8403\nEpoch 5/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 98ms/step\n\nEpoch 5 AUC: 0.8552\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef evaluate_model(model, dataset):\n    y_true = []\n    y_pred = []\n\n    for batch in dataset:\n        x = batch[:2]\n        y = tf.cast(batch[2], tf.int32).numpy()\n        preds = model(x, training=False).numpy()\n        preds = (preds > 0.5).astype(int).flatten()\n\n        y_true.extend(y)\n        y_pred.extend(preds)\n\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n\n    print(f\"Accuracy:  {acc:.4f}\")\n    print(f\"Precision: {prec:.4f}\")\n    print(f\"Recall:    {rec:.4f}\")\n    print(f\"F1 Score:  {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:53:02.411440Z","iopub.execute_input":"2025-07-04T07:53:02.411909Z","iopub.status.idle":"2025-07-04T07:53:02.417314Z","shell.execute_reply.started":"2025-07-04T07:53:02.411890Z","shell.execute_reply":"2025-07-04T07:53:02.416560Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"subset = train_pairs[:5000]\ntrain_subset = get_tf_dataset(subset)\nprint(\"\\nTraining Set Evaluation:\")\nevaluate_model(siamese_model, train_subset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T08:01:16.565763Z","iopub.execute_input":"2025-07-04T08:01:16.566052Z","iopub.status.idle":"2025-07-04T08:01:41.394803Z","shell.execute_reply.started":"2025-07-04T08:01:16.566033Z","shell.execute_reply":"2025-07-04T08:01:41.394104Z"}},"outputs":[{"name":"stdout","text":"\nTraining Set Evaluation:\nAccuracy:  0.9964\nPrecision: 0.9964\nRecall:    1.0000\nF1 Score:  0.9982\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"siamese_model.save(\"face_verifier.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T08:01:57.661380Z","iopub.execute_input":"2025-07-04T08:01:57.661626Z","iopub.status.idle":"2025-07-04T08:01:57.905878Z","shell.execute_reply.started":"2025-07-04T08:01:57.661608Z","shell.execute_reply":"2025-07-04T08:01:57.905318Z"}},"outputs":[],"execution_count":17}]}