{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12309085,"sourceType":"datasetVersion","datasetId":7758580}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training using MobileNetV2","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport tensorflow as tf\nfrom glob import glob\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Layer\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:40:04.499079Z","iopub.execute_input":"2025-07-01T12:40:04.499316Z","iopub.status.idle":"2025-07-01T12:40:26.906394Z","shell.execute_reply.started":"2025-07-01T12:40:04.499291Z","shell.execute_reply":"2025-07-01T12:40:26.905780Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 12:40:07.883821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751373608.338264      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751373608.450410      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:41:08.725772Z","iopub.execute_input":"2025-07-01T12:41:08.726377Z","iopub.status.idle":"2025-07-01T12:41:11.303809Z","shell.execute_reply.started":"2025-07-01T12:41:08.726355Z","shell.execute_reply":"2025-07-01T12:41:11.303183Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def get_all_images(root_dir):\n    person_images = {}\n    for person in os.listdir(root_dir):\n        person_path = os.path.join(root_dir, person)\n        if os.path.isdir(person_path):\n            distorted_folder = os.path.join(person_path, 'distortion')\n            distorted_images = glob(os.path.join(distorted_folder, '*.jpg'))\n            clean_images = [f for f in glob(os.path.join(person_path, '*.jpg')) if 'distortion' not in f]\n            if len(clean_images) >= 1 and len(distorted_images) >= 1:\n                person_images[person_path] = {\n                    'clean': clean_images,\n                    'distorted': distorted_images\n                }\n    return person_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:41:35.271772Z","iopub.execute_input":"2025-07-01T12:41:35.272324Z","iopub.status.idle":"2025-07-01T12:41:35.277451Z","shell.execute_reply.started":"2025-07-01T12:41:35.272300Z","shell.execute_reply":"2025-07-01T12:41:35.276767Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def create_pairs(person_images, num_neg_pairs=5000):\n    pairs = []\n    persons = list(person_images.keys())\n    for person in persons:\n        clean_imgs = person_images[person]['clean']\n        distorted_imgs = person_images[person]['distorted']\n        for c in clean_imgs:\n            for d in distorted_imgs:\n                pairs.append((c, d, 1))\n        for i in range(len(clean_imgs)):\n            for j in range(i + 1, len(clean_imgs)):\n                pairs.append((clean_imgs[i], clean_imgs[j], 1))\n        for i in range(len(distorted_imgs)):\n            for j in range(i + 1, len(distorted_imgs)):\n                pairs.append((distorted_imgs[i], distorted_imgs[j], 1))\n    while len([p for p in pairs if p[2] == 0]) < num_neg_pairs:\n        p1, p2 = random.sample(persons, 2)\n        img1 = random.choice(person_images[p1]['clean'] + person_images[p1]['distorted'])\n        img2 = random.choice(person_images[p2]['clean'] + person_images[p2]['distorted'])\n        pairs.append((img1, img2, 0))\n    return pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:41:55.855098Z","iopub.execute_input":"2025-07-01T12:41:55.855353Z","iopub.status.idle":"2025-07-01T12:41:55.861742Z","shell.execute_reply.started":"2025-07-01T12:41:55.855335Z","shell.execute_reply":"2025-07-01T12:41:55.860956Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def preprocess(path):\n    byte_img = tf.io.read_file(path)\n    img = tf.io.decode_jpeg(byte_img, channels=3)\n    img = tf.image.resize(img, (160, 160))\n    img = preprocess_input(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:42:20.243494Z","iopub.execute_input":"2025-07-01T12:42:20.243784Z","iopub.status.idle":"2025-07-01T12:42:20.248029Z","shell.execute_reply.started":"2025-07-01T12:42:20.243752Z","shell.execute_reply":"2025-07-01T12:42:20.247284Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocess_pair(path1, path2, label):\n    return (preprocess(path1), preprocess(path2), tf.convert_to_tensor(label))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:42:37.218468Z","iopub.execute_input":"2025-07-01T12:42:37.218767Z","iopub.status.idle":"2025-07-01T12:42:37.222803Z","shell.execute_reply.started":"2025-07-01T12:42:37.218738Z","shell.execute_reply":"2025-07-01T12:42:37.222137Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def get_tf_dataset(pairs):\n    path1 = [p[0] for p in pairs]\n    path2 = [p[1] for p in pairs]\n    labels = [p[2] for p in pairs]\n    ds1 = tf.data.Dataset.from_tensor_slices(path1)\n    ds2 = tf.data.Dataset.from_tensor_slices(path2)\n    lbls = tf.data.Dataset.from_tensor_slices(labels)\n    dataset = tf.data.Dataset.zip((ds1, ds2, lbls))\n    dataset = dataset.map(preprocess_pair, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.shuffle(2048).batch(64).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:42:54.801005Z","iopub.execute_input":"2025-07-01T12:42:54.801609Z","iopub.status.idle":"2025-07-01T12:42:54.806545Z","shell.execute_reply.started":"2025-07-01T12:42:54.801587Z","shell.execute_reply":"2025-07-01T12:42:54.805942Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class L1Dist(Layer):\n    def __init__(self, **kwargs):\n        super().__init__()\n    def call(self, input_embedding, validation_embedding):\n        return tf.math.abs(input_embedding - validation_embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:43:10.519722Z","iopub.execute_input":"2025-07-01T12:43:10.520050Z","iopub.status.idle":"2025-07-01T12:43:10.524436Z","shell.execute_reply.started":"2025-07-01T12:43:10.520027Z","shell.execute_reply":"2025-07-01T12:43:10.523882Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def make_embedding(trainable=False):\n    base_model = MobileNetV2(include_top=False, input_shape=(160, 160, 3), pooling='avg', weights='imagenet')\n    base_model.trainable = trainable\n    inputs = Input(shape=(160, 160, 3))\n    x = base_model(inputs)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(128, activation='sigmoid')(x)\n    return Model(inputs, x, name='MobileNetV2_Embedding')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:43:31.096814Z","iopub.execute_input":"2025-07-01T12:43:31.097113Z","iopub.status.idle":"2025-07-01T12:43:31.101550Z","shell.execute_reply.started":"2025-07-01T12:43:31.097093Z","shell.execute_reply":"2025-07-01T12:43:31.100770Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"embedding_model = make_embedding(trainable=False)\ndef make_siamese_model():\n    input_image = Input(name='input_img', shape=(160, 160, 3))\n    validation_image = Input(name='validation_img', shape=(160, 160, 3))\n    distances = L1Dist()(embedding_model(input_image), embedding_model(validation_image))\n    outputs = Dense(1, activation='sigmoid')(distances)\n    return Model(inputs=[input_image, validation_image], outputs=outputs, name='SiameseNetwork')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:44:01.407151Z","iopub.execute_input":"2025-07-01T12:44:01.407826Z","iopub.status.idle":"2025-07-01T12:44:05.017385Z","shell.execute_reply.started":"2025-07-01T12:44:01.407802Z","shell.execute_reply":"2025-07-01T12:44:05.016626Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1751373841.680352      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1751373841.681100      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"TRAIN_ROOT = \"/kaggle/input/comsys-taskb/Comys_Hackathon5/Task_B/train\"\ntrain_images = get_all_images(TRAIN_ROOT)\ntrain_pairs = create_pairs(train_images, num_neg_pairs=5000)\ntrain_pairs = random.sample(train_pairs, 200000)\ntrain_data = get_tf_dataset(train_pairs)\n\nsiamese_model = make_siamese_model()\nloss_fn = tf.losses.BinaryCrossentropy()\noptimizer = tf.keras.optimizers.Adam(1e-4)\ntrain_auc = tf.keras.metrics.AUC()\n\n@tf.function\ndef train_step(batch):\n    with tf.GradientTape() as tape:\n        x = batch[:2]\n        y = tf.cast(batch[2], tf.float32)\n        yhat = siamese_model(x, training=True)\n        loss = loss_fn(y, yhat)\n        train_auc.update_state(y, yhat)\n    gradients = tape.gradient(loss, siamese_model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, siamese_model.trainable_variables))\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T12:45:02.383017Z","iopub.execute_input":"2025-07-01T12:45:02.383347Z","iopub.status.idle":"2025-07-01T12:49:05.328398Z","shell.execute_reply.started":"2025-07-01T12:45:02.383327Z","shell.execute_reply":"2025-07-01T12:49:05.327843Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_model(train_data, epochs=5):\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        progbar = tf.keras.utils.Progbar(len(train_data))\n        for idx, batch in enumerate(train_data):\n            loss = train_step(batch)\n            progbar.update(idx + 1)\n        print(f\"\\nEpoch {epoch+1} AUC: {train_auc.result().numpy():.4f}\")\n        train_auc.reset_state()\n\n        # Unfreeze MobileNetV2 after 2 epochs\n        if epoch == 1:\n            print(\"\\nUnfreezing MobileNetV2 for fine-tuning...\")\n            base_model = embedding_model.get_layer('mobilenetv2_1.00_160')\n            base_model.trainable = True\n            for layer in base_model.layers[:100]:\n                layer.trainable = False\n            optimizer.learning_rate.assign(1e-5)\n\ntrain_model(train_data, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:52:29.137002Z","iopub.execute_input":"2025-07-01T13:52:29.137493Z","iopub.status.idle":"2025-07-01T14:19:51.959084Z","shell.execute_reply.started":"2025-07-01T13:52:29.137471Z","shell.execute_reply":"2025-07-01T14:19:51.958296Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 104ms/step\n\nEpoch 1 AUC: 0.9806\nEpoch 2/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 102ms/step\n\nEpoch 2 AUC: 0.9905\n\nUnfreezing MobileNetV2 for fine-tuning...\nEpoch 3/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 107ms/step\n\nEpoch 3 AUC: 0.9973\nEpoch 4/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 101ms/step\n\nEpoch 4 AUC: 0.9975\nEpoch 5/5\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 105ms/step\n\nEpoch 5 AUC: 0.9986\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"siamese_model.save(\"face_verifier.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T14:20:19.447552Z","iopub.execute_input":"2025-07-01T14:20:19.448071Z","iopub.status.idle":"2025-07-01T14:20:19.731740Z","shell.execute_reply.started":"2025-07-01T14:20:19.448049Z","shell.execute_reply":"2025-07-01T14:20:19.731219Z"}},"outputs":[],"execution_count":16}]}